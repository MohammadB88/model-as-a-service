apiVersion: capabilities.3scale.net/v1beta1
kind: Product
metadata:
  name: vllm-cpu-tinyllama
  namespace: 3scale
spec:
  name: "TinyLlama in vllm-gpu"
  systemName: "vllm-cpu-tinyllama"
  applicationPlans:
    standard:
      name: "Standard Plan"
      appsRequireApproval: false
      published: true
  methods:
    version:
      friendlyName: "Version"
      description: "vLLM Runtime Version"
    health:
      friendlyName: "Health"
      description: "vLLM Runtime Health"
    v1-models:
      friendlyName: "List Models"
      description: "List all models"
    v1-completions:
      friendlyName: Completions
      description: "Completions"
    v1-chat-completions:
      friendlyName: Chat Completions
      description: "Chat Completions"
    tokenize:
      friendlyName: Tokenize Text
      description: "Tokenize Text"
    detokenize:
      friendlyName: Detokenize Text
      description: "Detokenize Text"
  metrics:
    hits:
      description: Number of API hits
      friendlyName: Hits
      unit: hit
  mappingRules:
    - httpMethod: GET
      pattern: "/version"
      increment: 1
      metricMethodRef: version
    - httpMethod: GET
      pattern: "/health"
      increment: 1
      metricMethodRef: health
    - httpMethod: GET
      pattern: "/v1/models"
      increment: 1
      metricMethodRef: v1-models
    - httpMethod: POST
      pattern: "/v1/completions"
      increment: 1
      metricMethodRef: v1-completions
    - httpMethod: POST
      pattern: "/v1/chat/completions"
      increment: 1
      metricMethodRef: v1-chat-completions
    - httpMethod: POST
      pattern: "/tokenize"
      increment: 1
      metricMethodRef: tokenize
    - httpMethod: POST
      pattern: "/detokenize"
      increment: 1
      metricMethodRef: detokenize
  policies:
    - configuration: {}
      configurationRef: {}
      enabled: true
      name: corsrequesthandling
      version: builtin
    - configuration: {}
      configurationRef: {}
      enabled: true
      name: llmmonitor
      version: builtin
    - configuration: {}
      configurationRef: {}
      enabled: true
      name: apicast
      version: builtin
  backendUsages:
    vllm-gpu-mistral:
      path: /